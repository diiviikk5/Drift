// Studio Engine - Handles Post-Production (Zooming, Clicks, Export)
// Uses Rust-based zoom engine via Tauri IPC for desktop
// Falls back to simple playback for browser mode

import { isTauri } from './tauri-bridge';

const FRAME_SCALE = 0.82;
const TITLE_BAR_HEIGHT = 36;

export class StudioEngine {
    constructor(canvas, videoElement, blob, clicks = [], duration = null, mouseMoves = []) {
        console.log('[Studio] Initializing with', clicks.length, 'clicks, duration:', duration);

        this.canvas = canvas;
        this.ctx = canvas.getContext('2d', { alpha: false, desynchronized: true });
        this.video = videoElement;

        // Cached background gradient (rebuilt only when bg changes or canvas resizes)
        this._cachedBg = null;
        this._cachedBgKey = '';

        this.blob = blob;
        this.clicks = clicks;
        this.explicitDuration = duration;
        this.mouseMoves = mouseMoves;

        // Camera state — starts FULLY panned out (scale 1.0)
        this.camera = { x: 0.5, y: 0.5, scale: 1 };

        // Cursor state from Rust
        this.cursorState = { x: 0.5, y: 0.5, opacity: 0.0, click_progress: 0.0, motion: 0.0 };

        // Zoom segments (generated by Rust)
        this.zoomSegments = [];

        // Tauri mode detection
        this.isTauri = false;
        this.tauriReady = false;

        // Customizable settings
        this.background = 'bigSur';
        this.startPosition = 'center';
        this.trimStart = 0;
        this.trimEnd = 0;
        this.showCursor = false;
        this.zoomLevel = 2.0;

        // Precomputed frames for export (array of FrameState from Rust)
        this.precomputedFrames = null;

        this.isPlaying = false;
        this.animationFrame = null;

        this._initTauri();
        this.init();
    }

    async _initTauri() {
        try {
            if (!isTauri()) {
                console.log('[Studio] Browser mode — simple playback (no zoom engine)');
                return;
            }
            const { invoke } = await import('@tauri-apps/api/core');
            this.isTauri = true;
            this.tauriInvoke = invoke;
            console.log('[Studio] Tauri mode — using Rust zoom engine');

            // Generate zoom segments in Rust
            await this._generateSegments();
            this.tauriReady = true;
        } catch {
            console.log('[Studio] Browser fallback — no Tauri available');
        }
    }

    async _generateSegments() {
        if (!this.tauriInvoke) return;

        try {
            const clickEvents = this.clicks.map(c => ({
                time: c.time,
                x: c.x,
                y: c.y,
                down: true,
            }));

            const moveEvents = (this.mouseMoves || []).map(m => ({
                time: m.time,
                x: m.x,
                y: m.y,
            }));

            const durationMs = (this.explicitDuration || 10) * 1000;

            this.zoomSegments = await this.tauriInvoke('generate_zoom_segments', {
                clicks: clickEvents,
                moves: moveEvents,
                durationMs: durationMs,
            });

            console.log('[Studio] Rust generated', this.zoomSegments.length, 'zoom segments');
        } catch (e) {
            console.error('[Studio] Segment generation failed:', e);
            this.zoomSegments = [];
        }
    }

    init() {
        console.log('[Studio] init() called');
        this.video.src = URL.createObjectURL(this.blob);
        this.video.muted = false;

        this.video.onloadedmetadata = () => {
            console.log('[Studio] Video metadata loaded, duration:', this.video.duration);
            this.canvas.width = this.video.videoWidth || 1920;
            this.canvas.height = this.video.videoHeight || 1080;

            if (this.explicitDuration) {
                this.videoDuration = this.explicitDuration;
            } else if (!isFinite(this.video.duration)) {
                const lastClick = this.clicks[this.clicks.length - 1];
                this.videoDuration = lastClick ? (lastClick.time / 1000 + 2) : 10;
            } else {
                this.videoDuration = this.video.duration;
            }
            console.log('[Studio] Using duration:', this.videoDuration);
            this.drawFrame();
        };

        this.video.onplay = () => {
            this.isPlaying = true;
            this.renderLoop();
        };
        this.video.onpause = () => {
            this.isPlaying = false;
            cancelAnimationFrame(this.animationFrame);
        };
        this.video.onended = () => {
            this.isPlaying = false;
        };
    }

    play() {
        this.video.play().catch(e => console.error('[Studio] Play failed:', e));
    }

    pause() {
        this.video.pause();
    }

    resetCamera() {
        this.camera = { x: 0.5, y: 0.5, scale: 1 };
        this.cursorState = { x: 0.5, y: 0.5, opacity: 0.0, click_progress: 0.0, motion: 0.0 };
    }

    async addZoom(timeSec, x = 0.5, y = 0.5, scale = 1.5) {
        this.clicks.push({ time: timeSec * 1000, x, y, scale });
        this.clicks.sort((a, b) => a.time - b.time);

        // Regenerate segments in Rust
        await this._generateSegments();

        if (!this.isPlaying) {
            await this.updateCamera();
            this.drawFrame();
        }
    }

    updateClick(index, updates) {
        if (index < 0 || index >= this.clicks.length) return;
        Object.assign(this.clicks[index], updates);
        this._generateSegments().then(() => {
            if (!this.isPlaying) {
                this.updateCamera();
                this.drawFrame();
            }
        });
    }

    resolveClick(normX, normY) {
        const Px = normX * this.canvas.width;
        const Py = normY * this.canvas.height;
        const P1x = Px - this.canvas.width / 2;
        const P1y = Py - this.canvas.height / 2;
        const P2x = P1x / this.camera.scale;
        const P2y = P1y / this.camera.scale;
        const vw = this.canvas.width * FRAME_SCALE;
        const vRatio = this.video.videoHeight / this.video.videoWidth;
        const vh = vw * vRatio;
        const totalHeight = vh + TITLE_BAR_HEIGHT;
        const panX = (this.camera.x - 0.5) * vw;
        const panY = (this.camera.y - 0.5) * totalHeight;
        const P3x = P2x + panX;
        const P3y = P2y + panY;
        const winX = -vw / 2;
        const winY = -totalHeight / 2;
        const videoX = winX;
        const videoY = winY + TITLE_BAR_HEIGHT;
        const relX = P3x - videoX;
        const relY = P3y - videoY;
        const finalX = relX / vw;
        const finalY = relY / vh;
        return {
            x: Math.max(0, Math.min(1, finalX)),
            y: Math.max(0, Math.min(1, finalY))
        };
    }

    renderLoop() {
        let frameCount = 0;
        const loop = () => {
            frameCount++;
            this.updateCamera();
            this.drawFrame();
            if (this.isPlaying) this.animationFrame = requestAnimationFrame(loop);
        };
        loop();
    }

    async updateCamera() {
        const currentMs = this.video.currentTime * 1000;

        if (this.isTauri && this.tauriReady) {
            try {
                // Single Rust call for both zoom and cursor state
                const state = await this.tauriInvoke('evaluate_frame', {
                    segments: this.zoomSegments,
                    moves: (this.mouseMoves || []).map(m => ({ time: m.time, x: m.x, y: m.y })),
                    clicks: this.clicks.map(c => ({ time: c.time, x: c.x, y: c.y, down: true })),
                    timeMs: currentMs,
                });

                this.camera = {
                    x: state.zoom.x,
                    y: state.zoom.y,
                    scale: state.zoom.scale,
                };
                this.cursorState = state.cursor;
            } catch (e) {
                // Fallback: no zoom
                this.camera = { x: 0.5, y: 0.5, scale: 1 };
            }
        } else {
            // Browser mode: no zoom, just basic cursor position from raw data
            this.camera = { x: 0.5, y: 0.5, scale: 1 };
            this._updateBrowserCursor(currentMs);
        }
    }

    // Simple browser fallback cursor (no spring, no zoom)
    _updateBrowserCursor(timeMs) {
        if (!this.mouseMoves || this.mouseMoves.length === 0) {
            this.cursorState = { x: 0.5, y: 0.5, opacity: 0.0, click_progress: 0.0, motion: 0.0 };
            return;
        }

        // Find nearest move
        let bestMove = this.mouseMoves[0];
        for (const m of this.mouseMoves) {
            if (m.time <= timeMs) bestMove = m;
            else break;
        }

        this.cursorState = {
            x: bestMove.x,
            y: bestMove.y,
            opacity: 1.0,
            click_progress: 0.0,
            motion: 0.0,
        };
    }

    // Static background definitions (created once, not per-frame)
    static BACKGROUNDS = {
        bigSur: {
            type: 'radial',
            colors: [
                { pos: 0, color: '#ff6b9d' },
                { pos: 0.3, color: '#c44569' },
                { pos: 0.5, color: '#6c5ce7' },
                { pos: 0.8, color: '#0c3483' },
                { pos: 1, color: '#1a1a2e' }
            ]
        },
        monterey: {
            type: 'radial',
            colors: [
                { pos: 0, color: '#00b894' },
                { pos: 0.25, color: '#00cec9' },
                { pos: 0.5, color: '#0984e3' },
                { pos: 0.8, color: '#6c5ce7' },
                { pos: 1, color: '#2d1b4e' }
            ]
        },
        ventura: {
            type: 'diagonal',
            colors: [
                { pos: 0, color: '#e17055' },
                { pos: 0.3, color: '#d63031' },
                { pos: 0.5, color: '#fd79a8' },
                { pos: 0.7, color: '#a855f7' },
                { pos: 1, color: '#1e3a5f' }
            ]
        },
        bloom: {
            type: 'radial',
            colors: [
                { pos: 0, color: '#74b9ff' },
                { pos: 0.3, color: '#0984e3' },
                { pos: 0.5, color: '#6c5ce7' },
                { pos: 0.7, color: '#a855f7' },
                { pos: 1, color: '#1a1a2e' }
            ]
        },
        sonoma: {
            type: 'diagonal',
            colors: [
                { pos: 0, color: '#fdcb6e' },
                { pos: 0.25, color: '#f39c12' },
                { pos: 0.5, color: '#e74c3c' },
                { pos: 0.75, color: '#9b59b6' },
                { pos: 1, color: '#2c3e50' }
            ]
        },
        midnight: {
            type: 'radial',
            colors: [
                { pos: 0, color: '#2c3e50' },
                { pos: 0.5, color: '#1a1a2e' },
                { pos: 1, color: '#0a0a0f' }
            ]
        }
    };

    _getBackgroundGradient() {
        const c = this.canvas;
        const ctx = this.ctx;
        const key = `${this.background}_${c.width}_${c.height}`;
        if (this._cachedBgKey === key && this._cachedBg) return this._cachedBg;

        const bgConfig = StudioEngine.BACKGROUNDS[this.background] || StudioEngine.BACKGROUNDS.bigSur;
        let gradient;
        if (bgConfig.type === 'radial') {
            gradient = ctx.createRadialGradient(
                c.width * 0.3, c.height * 0.3, 0,
                c.width * 0.5, c.height * 0.5, c.width * 0.8
            );
        } else {
            gradient = ctx.createLinearGradient(0, 0, c.width, c.height);
        }
        bgConfig.colors.forEach(({ pos, color }) => gradient.addColorStop(pos, color));
        this._cachedBg = gradient;
        this._cachedBgKey = key;
        return gradient;
    }

    drawFrame() {
        const c = this.canvas;
        const ctx = this.ctx;
        const v = this.video;
        const cam = this.camera;

        ctx.fillStyle = this._getBackgroundGradient();
        ctx.fillRect(0, 0, c.width, c.height);

        if (v.readyState >= 2) {
            ctx.save();

            const titleBarHeight = TITLE_BAR_HEIGHT;
            const vw = c.width * FRAME_SCALE;
            const vh = (v.videoHeight / v.videoWidth) * vw;
            const totalHeight = vh + titleBarHeight;

            const cx = c.width / 2;
            const cy = c.height / 2;

            // Apply Camera Transform
            ctx.translate(cx, cy);
            ctx.scale(cam.scale, cam.scale);

            const panX = (cam.x - 0.5) * vw;
            const panY = (cam.y - 0.5) * totalHeight;
            ctx.translate(-panX, -panY);

            const r = 12;
            const x = -vw / 2;
            const y = -totalHeight / 2;
            const w = vw;
            const h = totalHeight;

            // Shadow
            ctx.shadowColor = 'rgba(0,0,0,0.6)';
            ctx.shadowBlur = 60;
            ctx.shadowOffsetY = 25;

            ctx.fillStyle = '#1a1a1a';
            this.roundRect(ctx, x, y, w, h, r);
            ctx.fill();

            ctx.shadowColor = 'transparent';

            // Title Bar
            ctx.save();
            this.roundRect(ctx, x, y, w, titleBarHeight, { tl: r, tr: r, bl: 0, br: 0 });
            ctx.clip();

            ctx.fillStyle = '#2d2d2d';
            ctx.fillRect(x, y, w, titleBarHeight);

            const bx = x + 18;
            const by = y + titleBarHeight / 2;
            const gap = 20;
            const dotRadius = 6;

            ctx.fillStyle = '#FF5F57';
            ctx.beginPath(); ctx.arc(bx, by, dotRadius, 0, Math.PI * 2); ctx.fill();
            ctx.fillStyle = '#FFBD2E';
            ctx.beginPath(); ctx.arc(bx + gap, by, dotRadius, 0, Math.PI * 2); ctx.fill();
            ctx.fillStyle = '#28C840';
            ctx.beginPath(); ctx.arc(bx + gap * 2, by, dotRadius, 0, Math.PI * 2); ctx.fill();

            ctx.restore();

            // Video Area
            ctx.save();
            ctx.beginPath();
            ctx.rect(x, y + titleBarHeight, w, vh);
            ctx.clip();

            ctx.drawImage(v, x, y + titleBarHeight, w, vh);

            // Draw cursor overlay (from Rust state)
            if (this.showCursor && this.cursorState.opacity > 0.01) {
                const cursorX = x + this.cursorState.x * w;
                const cursorY = y + titleBarHeight + this.cursorState.y * vh;
                ctx.globalAlpha = this.cursorState.opacity;

                if (this.cursorState.click_progress > 0.01) {
                    this.drawClickRing(ctx, cursorX, cursorY, this.cursorState.click_progress);
                }

                this.drawCursor(ctx, cursorX, cursorY, this.cursorState.motion, this.cursorState.click_progress);
                ctx.globalAlpha = 1;
            }

            ctx.restore();

            // Border
            ctx.strokeStyle = 'rgba(255,255,255,0.15)';
            ctx.lineWidth = 1;
            this.roundRect(ctx, x, y, w, h, r);
            ctx.stroke();

            ctx.restore();
        }
    }

    drawClickRing(ctx, x, y, progress) {
        ctx.save();
        const radius = 8 + progress * 20;
        const alpha = (1 - progress) * 0.5;
        ctx.beginPath();
        ctx.arc(x, y, radius, 0, Math.PI * 2);
        ctx.strokeStyle = `rgba(255, 255, 255, ${alpha})`;
        ctx.lineWidth = 2 * (1 - progress * 0.5);
        ctx.stroke();
        ctx.beginPath();
        ctx.arc(x, y, radius * 0.5, 0, Math.PI * 2);
        ctx.fillStyle = `rgba(255, 255, 255, ${alpha * 0.3})`;
        ctx.fill();
        ctx.restore();
    }

    drawCursor(ctx, x, y, motion = 0, clickProgress = 0) {
        ctx.save();
        ctx.translate(x, y);

        const clickScale = clickProgress > 0 ? 1 - clickProgress * 0.2 : 1;
        ctx.scale(clickScale, clickScale);

        const motionScale = 1 + motion * 0.12;
        ctx.scale(1, motionScale);

        ctx.shadowColor = 'rgba(0,0,0,0.5)';
        ctx.shadowBlur = 8 + motion * 12;
        ctx.shadowOffsetX = 2;
        ctx.shadowOffsetY = 2;

        // macOS-style pointer cursor
        ctx.beginPath();
        ctx.moveTo(0, 0);
        ctx.lineTo(0, 20);
        ctx.lineTo(5, 15);
        ctx.lineTo(9, 22);
        ctx.lineTo(12, 20);
        ctx.lineTo(8, 13);
        ctx.lineTo(14, 13);
        ctx.closePath();

        ctx.strokeStyle = '#ffffff';
        ctx.lineWidth = 2;
        ctx.stroke();

        ctx.fillStyle = '#000000';
        ctx.fill();

        ctx.restore();
    }

    roundRect(ctx, x, y, w, h, r) {
        ctx.beginPath();
        ctx.roundRect(x, y, w, h, r);
        ctx.closePath();
    }

    // --- EXPORT FUNCTION (MP4 via WebCodecs, WebM fallback) ---
    async exportVideo(onProgress) {
        // Try WebCodecs MP4 first (no ffmpeg, hardware-accelerated)
        if (typeof VideoEncoder !== 'undefined') {
            try {
                return await this._exportMP4(onProgress);
            } catch (e) {
                console.warn('[Studio] WebCodecs MP4 export failed, falling back to WebM:', e.message);
            }
        }
        // Fallback: WebM via MediaRecorder
        return await this._exportWebM(onProgress);
    }

    // --- WebCodecs + mp4-muxer → direct MP4 blob (no ffmpeg) ---
    async _exportMP4(onProgress) {
        const { Muxer, ArrayBufferTarget } = await import('mp4-muxer');

        this.video.pause();
        this.video.currentTime = this.trimStart || 0;
        this.camera = { x: 0.5, y: 0.5, scale: 1 };
        await this._generateSegments();
        await new Promise(r => setTimeout(r, 300));

        const exportDuration = (this.trimEnd || this.videoDuration) - (this.trimStart || 0);
        const fps = 60;
        const width = this.canvas.width;
        const height = this.canvas.height;

        // Precompute frames in Rust
        if (this.isTauri && this.tauriReady) {
            try {
                this.precomputedFrames = await this.tauriInvoke('precompute_frames', {
                    segments: this.zoomSegments,
                    moves: (this.mouseMoves || []).map(m => ({ time: m.time, x: m.x, y: m.y })),
                    clicks: this.clicks.map(c => ({ time: c.time, x: c.x, y: c.y, down: true })),
                    durationMs: exportDuration * 1000,
                    fps,
                });
                console.log('[Studio] Precomputed', this.precomputedFrames.length, 'frames for export');
            } catch (e) {
                console.error('[Studio] Precompute failed:', e);
                this.precomputedFrames = null;
            }
        }

        const totalFrames = Math.ceil(exportDuration * fps);
        const frameDurationUs = 1_000_000 / fps;

        // Target bitrate: scale with resolution for consistent quality
        const isHD = width >= 1920;
        const targetBitrate = isHD ? 30_000_000 : 15_000_000; // 30Mbps for 1080p+, 15 for lower

        // Find a supported H.264 codec — try highest profile first (best quality)
        const profiles = ['avc1.640028', 'avc1.4d001f', 'avc1.42001f'];
        let codecConfig = null;
        for (const codec of profiles) {
            try {
                const support = await VideoEncoder.isConfigSupported({
                    codec, width, height,
                    bitrate: targetBitrate,
                    bitrateMode: 'constant',
                    framerate: fps,
                    latencyMode: 'quality',
                    hardwareAcceleration: 'prefer-hardware',
                    avc: { format: 'avc' },
                });
                if (support.supported) {
                    codecConfig = support.config;
                    console.log('[Studio] Using H.264 profile:', codec);
                    break;
                }
            } catch { continue; }
        }
        if (!codecConfig) throw new Error('No supported H.264 profile');

        console.log('[Studio] Exporting MP4 via WebCodecs:', width, 'x', height, '@', fps, 'fps,', (targetBitrate / 1_000_000) + 'Mbps');

        const target = new ArrayBufferTarget();
        const muxer = new Muxer({
            target,
            video: { codec: 'avc', width, height },
            fastStart: 'in-memory',
        });

        return new Promise((resolve, reject) => {
            const encoder = new VideoEncoder({
                output: (chunk, meta) => muxer.addVideoChunk(chunk, meta),
                error: (e) => reject(e),
            });
            encoder.configure({
                ...codecConfig,
                hardwareAcceleration: 'prefer-hardware',
                latencyMode: 'quality',
                bitrateMode: 'constant',
                bitrate: targetBitrate,
            });

            let frameIndex = 0;
            this.video.currentTime = this.trimStart || 0;

            const seekAndRender = () => {
                return new Promise(seekResolve => {
                    const targetTime = (this.trimStart || 0) + (frameIndex / fps);
                    if (targetTime >= (this.trimEnd || this.videoDuration) || frameIndex >= totalFrames) {
                        seekResolve(false);
                        return;
                    }

                    this.video.currentTime = targetTime;
                    const onSeeked = () => {
                        this.video.removeEventListener('seeked', onSeeked);

                        // Apply precomputed or live camera state
                        if (this.precomputedFrames && frameIndex < this.precomputedFrames.length) {
                            const state = this.precomputedFrames[frameIndex];
                            this.camera = { x: state.zoom.x, y: state.zoom.y, scale: state.zoom.scale };
                            this.cursorState = state.cursor;
                        } else {
                            this.updateCamera();
                        }
                        this.drawFrame();

                        // Encode the canvas frame
                        const timestamp = Math.round(frameIndex * frameDurationUs);
                        const frame = new VideoFrame(this.canvas, {
                            timestamp,
                            duration: Math.round(frameDurationUs),
                        });
                        // Keyframe every 1 second for better seeking + quality
                        encoder.encode(frame, { keyFrame: frameIndex % fps === 0 });
                        frame.close();

                        frameIndex++;
                        if (onProgress) {
                            const p = Math.min(frameIndex / totalFrames, 1);
                            if (isFinite(p)) onProgress(p);
                        }
                        seekResolve(true);
                    };
                    this.video.addEventListener('seeked', onSeeked);
                });
            };

            const processFrames = async () => {
                try {
                    while (true) {
                        const hasMore = await seekAndRender();
                        if (!hasMore) break;
                    }

                    await encoder.flush();
                    encoder.close();
                    muxer.finalize();

                    this.precomputedFrames = null;
                    const mp4Blob = new Blob([target.buffer], { type: 'video/mp4' });
                    console.log('[Studio] MP4 export complete:', (mp4Blob.size / 1024 / 1024).toFixed(1), 'MB');
                    resolve(mp4Blob);
                } catch (e) {
                    reject(e);
                }
            };

            processFrames();
        });
    }

    // --- WebM fallback via MediaRecorder ---
    async _exportWebM(onProgress) {
        this.video.pause();
        this.video.currentTime = this.trimStart || 0;
        this.camera = { x: 0.5, y: 0.5, scale: 1 };
        await this._generateSegments();
        await new Promise(r => setTimeout(r, 300));

        const exportDuration = (this.trimEnd || this.videoDuration) - (this.trimStart || 0);
        const fps = 60;

        // Precompute frames in Rust
        if (this.isTauri && this.tauriReady) {
            try {
                this.precomputedFrames = await this.tauriInvoke('precompute_frames', {
                    segments: this.zoomSegments,
                    moves: (this.mouseMoves || []).map(m => ({ time: m.time, x: m.x, y: m.y })),
                    clicks: this.clicks.map(c => ({ time: c.time, x: c.x, y: c.y, down: true })),
                    durationMs: exportDuration * 1000,
                    fps,
                });
                console.log('[Studio] Precomputed', this.precomputedFrames.length, 'frames for export');
            } catch (e) {
                console.error('[Studio] Precompute failed:', e);
                this.precomputedFrames = null;
            }
        }

        const chunks = [];
        const mimeType = MediaRecorder.isTypeSupported('video/webm;codecs=vp8,opus')
            ? 'video/webm;codecs=vp8,opus'
            : 'video/webm';

        const stream = this.canvas.captureStream(0);
        if (this.video.captureStream) {
            try {
                const videoStream = this.video.captureStream();
                videoStream.getAudioTracks().forEach(track => stream.addTrack(track));
            } catch (e) {
                console.log('[Studio] Could not capture audio:', e);
            }
        }

        const rec = new MediaRecorder(stream, { mimeType, videoBitsPerSecond: 20_000_000 });
        rec.ondataavailable = e => { if (e.data.size > 0) chunks.push(e.data); };

        return new Promise(async (resolve) => {
            rec.onstop = () => {
                const blob = new Blob(chunks, { type: 'video/webm' });
                this.precomputedFrames = null;
                resolve(blob);
            };

            rec.start();
            this.video.play();
            this.isPlaying = true;
            let frameIndex = 0;

            const renderExport = () => {
                if (this.video.ended || this.video.currentTime >= (this.trimEnd || this.videoDuration)) {
                    this.isPlaying = false;
                    this.video.pause();
                    rec.stop();
                    return;
                }

                if (this.precomputedFrames && frameIndex < this.precomputedFrames.length) {
                    const state = this.precomputedFrames[frameIndex];
                    this.camera = { x: state.zoom.x, y: state.zoom.y, scale: state.zoom.scale };
                    this.cursorState = state.cursor;
                } else {
                    this.updateCamera();
                }

                this.drawFrame();
                frameIndex++;

                const canvasTrack = stream.getVideoTracks().find(t => t.kind === 'video');
                if (canvasTrack?.requestFrame) canvasTrack.requestFrame();

                const currentTime = this.video.currentTime - (this.trimStart || 0);
                const progress = Math.min(Math.max(currentTime / exportDuration, 0), 1);
                if (onProgress && isFinite(progress)) onProgress(progress);

                requestAnimationFrame(renderExport);
            };

            renderExport();
        });
    }
}
